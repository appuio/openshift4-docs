= Install OpenShift 4 on cloudscale.ch
:ocp-minor-version: 4.13
:k8s-minor-version: 1.26
:ocp-patch-version: {ocp-minor-version}.0
:provider: cloudscale

[abstract]
--
Steps to install an OpenShift 4 cluster on https://cloudscale.ch[cloudscale.ch].

These steps follow the https://docs.openshift.com/container-platform/latest/installing/installing_bare_metal/installing-bare-metal.html[Installing a cluster on bare metal] docs to set up a user provisioned installation (UPI).
https://www.terraform.io[Terraform] is used to provision the cloud infrastructure.
--

[NOTE]
--
The commands are idempotent and can be retried if any of the steps fail.

The certificates created during bootstrap are only valid for 24h.
So make sure you complete these steps within 24h.
--

[NOTE]
--
This how-to guide is still a work in progress and will change.
It's currently very specific to VSHN and needs further changes to be more generic.
--

== Starting situation

* You already have a Tenant and its git repository
* You have a CCSP Red Hat login and are logged into https://cloud.redhat.com/openshift/install/metal/user-provisioned[Red Hat Openshift Cluster Manager]
+
IMPORTANT: Don't use your personal account to login to the cluster manager for installation.
* You want to register a new cluster in Lieutenant and are about to install Openshift 4 on cloudscale.ch

== Prerequisites

include::partial$install/prerequisites.adoc[]
* `mc` https://docs.min.io/docs/minio-client-quickstart-guide.html[Minio client] (aliased to `mc` if necessary)

[WARNING]
====
Make sure the minor version of `openshift-install` and the RHCOS image are the same as ignition will fail otherwise.
====

== Cluster Installation

include::partial$install/register.adoc[]

=== Configure input

.Access to cloud API
[source,bash]
----
# https://control.cloudscale.ch/service/<your-project>/api-token
export CLOUDSCALE_API_TOKEN=<cloudscale-api-token>
export TF_VAR_lb_cloudscale_api_secret=<cloudscale-api-token-for-Floaty>
----

include::partial$install/vshn-input.adoc[]

[#_bootstrap_bucket]
=== Set up S3 bucket for cluster bootstrap

. Create S3 bucket

.. If a bucket user already exists for this cluster:
+
[source,bash]
----
# Use already existing bucket user
response=$(curl -sH "Authorization: Bearer ${CLOUDSCALE_API_TOKEN}" \
  https://api.cloudscale.ch/v1/objects-users | \
  jq -e ".[] | select(.display_name == \"${CLUSTER_ID}\")")
----

.. To create a new bucket user:
+
[source,bash]
----
# Create a new user
response=$(curl -sH "Authorization: Bearer ${CLOUDSCALE_API_TOKEN}" \
  -F display_name=${CLUSTER_ID} \
  https://api.cloudscale.ch/v1/objects-users)
----

. Configure the Minio client
+
[source,bash]
----
export REGION=$(curl -sH "Authorization: Bearer $(commodore fetch-token)" ${COMMODORE_API_URL}/clusters/${CLUSTER_ID} | jq -r .facts.region)
mc config host add \
  "${CLUSTER_ID}" "https://objects.${REGION}.cloudscale.ch" \
  $(echo $response | jq -r '.keys[0].access_key') \
  $(echo $response | jq -r '.keys[0].secret_key')

mc mb --ignore-existing \
  "${CLUSTER_ID}/${CLUSTER_ID}-bootstrap-ignition"
----

[#_upload_coreos_image]
=== Upload Red Hat CoreOS image

. Export the Authorization header for the cloudscale.ch API.
+
[source,bash]
----
export AUTH_HEADER="Authorization: Bearer ${CLOUDSCALE_API_TOKEN}"
----
+
[NOTE]
====
The variable `CLOUDSCALE_API_TOKEN` could be used directly.
Exporting the variable `AUTH_HEADER` is done to be compatible with the https://www.cloudscale.ch/en/api/[cloudscale.ch API documentation].
====

. Check if image already exists in the correct zone
+
[source,bash,subs="attributes+"]
----
curl -sH "$AUTH_HEADER" https://api.cloudscale.ch/v1/custom-images | jq -r '.[] | select(.slug == "rhcos-{ocp-minor-version}") | .zones[].slug'
----
+
[NOTE]
====
If a URL is printed to the output, you can skip the next steps and directly jump to the next section.
====

. Fetch the latest Red Hat CoreOS image
+
[source,bash,subs="attributes+"]
----
curl -L https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/{ocp-minor-version}/{ocp-patch-version}/rhcos-{ocp-patch-version}-x86_64-openstack.x86_64.qcow2.gz | gzip -d > rhcos-{ocp-minor-version}.qcow2
----

. Upload the image to S3 and make it public
+
[source,bash,subs="attributes+"]
----
mc cp rhcos-{ocp-minor-version}.qcow2 "$\{CLUSTER_ID\}/$\{CLUSTER_ID\}-bootstrap-ignition/"
mc anonymous set download "$\{CLUSTER_ID\}/$\{CLUSTER_ID\}-bootstrap-ignition/rhcos-{ocp-minor-version}.qcow2"
----
+
[TIP]
====
You can check that the download policy is applied successfully with

[source,bash,subs="attributes+"]
----
mc anonymous get "$\{CLUSTER_ID\}/$\{CLUSTER_ID\}-bootstrap-ignition/rhcos-{ocp-minor-version}.qcow2"
----

The output should be

[source,subs="attributes+"]
----
`Access permission for `[â€¦]-bootstrap-ignition/rhcos-{ocp-minor-version}.qcow2` is `download``
----
====

. Import the image to cloudscale.ch
+
[source,bash,subs="attributes+"]
----
curl -i -H "$AUTH_HEADER" \
  -F url="$(mc share download --json "$\{CLUSTER_ID\}/$\{CLUSTER_ID\}-bootstrap-ignition/rhcos-{ocp-minor-version}.qcow2" | jq -r .url)" \
  -F name='RHCOS {ocp-minor-version}' \
  -F zones="${REGION}1" \
  -F slug=rhcos-{ocp-minor-version} \
  -F source_format=qcow2 \
  -F user_data_handling=pass-through \
  https://api.cloudscale.ch/v1/custom-images/import
----

[#_set_vault_secrets]
=== Set secrets in Vault

include::partial$connect-to-vault.adoc[]

.Store various secrets in Vault
[source,bash]
----
# Set the cloudscale.ch access secrets
vault kv put clusters/kv/${TENANT_ID}/${CLUSTER_ID}/cloudscale \
  token=${CLOUDSCALE_API_TOKEN} \
  s3_access_key=$(mc config host ls ${CLUSTER_ID} -json | jq -r .accessKey) \
  s3_secret_key=$(mc config host ls ${CLUSTER_ID} -json | jq -r .secretKey)

# Put LB API key in Vault
vault kv put clusters/kv/${TENANT_ID}/${CLUSTER_ID}/floaty \
  iam_secret=${TF_VAR_lb_cloudscale_api_secret}

# Generate an HTTP secret for the registry
vault kv put clusters/kv/${TENANT_ID}/${CLUSTER_ID}/registry \
  httpSecret=$(LC_ALL=C tr -cd "A-Za-z0-9" </dev/urandom | head -c 128)

# Set the LDAP password
vault kv put clusters/kv/${TENANT_ID}/${CLUSTER_ID}/vshn-ldap \
  bindPassword=${LDAP_PASSWORD}

# Generate a master password for K8up backups
vault kv put clusters/kv/${TENANT_ID}/${CLUSTER_ID}/global-backup \
  password=$(LC_ALL=C tr -cd "A-Za-z0-9" </dev/urandom | head -c 32)

# Generate a password for the cluster object backups
vault kv put clusters/kv/${TENANT_ID}/${CLUSTER_ID}/cluster-backup \
  password=$(LC_ALL=C tr -cd "A-Za-z0-9" </dev/urandom | head -c 32)

# Copy the Dagobert OpenShift Node Collector Credentials
vault kv get -format=json "clusters/kv/template/dagobert" | jq '.data.data' \
  | vault kv put -cas=0 "clusters/kv/${TENANT_ID}/${CLUSTER_ID}/dagobert" -

# Copy the VSHN acme-dns registration password
vault kv get -format=json "clusters/kv/template/cert-manager" | jq '.data.data' \
  | vault kv put -cas=0 "clusters/kv/${TENANT_ID}/${CLUSTER_ID}/cert-manager" -
----

include::partial$get-hieradata-token-from-vault.adoc[]

include::partial$install/prepare-commodore.adoc[]

[#_configure_installer]
=== Configure the OpenShift Installer

include::partial$install/configure-installer.adoc[]

[#_run_installer]
=== Run the OpenShift Installer

include::partial$install/run-installer.adoc[]

. Upload ignition config
+
[source,bash]
----
mc cp "${INSTALLER_DIR}/bootstrap.ign" "${CLUSTER_ID}/${CLUSTER_ID}-bootstrap-ignition/"

export TF_VAR_ignition_bootstrap=$(mc share download \
  --json --expire=4h \
  "${CLUSTER_ID}/${CLUSTER_ID}-bootstrap-ignition/bootstrap.ign" | jq -r '.share')
----

=== Terraform Cluster Config

include::partial$install/prepare-syn-config.adoc[]

=== Provision Infrastructure

include::partial$cloudscale/configure-terraform-secrets.adoc[]

include::partial$setup_terraform.adoc[]

. Create LB hieradata
+
[source,bash]
----
cat > override.tf <<EOF
module "cluster" {
  bootstrap_count          = 0
  master_count             = 0
  infra_count              = 0
  worker_count             = 0
  additional_worker_groups = {}
}
EOF
terraform apply -target "module.cluster.module.lb.module.hiera"
----

. Review and merge the LB hieradata MR (listed in Terraform output `hieradata_mr`) and wait until the deploy pipeline after the merge is completed.

. Create LBs
+
[source,bash]
----
terraform apply
----

. Setup the DNS records shown in output variable `dns_entries` from the previous step in the cluster's parent zone.
If you use a custom apps domain, make the necessary changes to the DNS record for `*.apps`.

. Make LB FQDNs available for later steps
+
.Store LB FQDNs in environment
[source,bash]
----
declare -a LB_FQDNS
for id in 1 2; do
  LB_FQDNS[$id]=$(terraform state show "module.cluster.module.lb.cloudscale_server.lb[$(expr $id - 1)]" | grep fqdn | awk '{print $2}' | tr -d ' "\r\n')
done
----
+
.Verify FQDNs
[source,bash]
----
for lb in "${LB_FQDNS[@]}"; do echo $lb; done
----

include::partial$install/bootstrap-lb.adoc[]

include::partial$install/bootstrap-nodes.adoc[]

. Create secret with S3 credentials https://docs.openshift.com/container-platform/{ocp-minor-version}/registry/configuring_registry_storage/configuring-registry-storage-aws-user-infrastructure.html#registry-operator-config-resources-secret-aws_configuring-registry-storage-aws-user-infrastructure[for the registry]
+
[source,bash]
----
oc create secret generic image-registry-private-configuration-user \
--namespace openshift-image-registry \
--from-literal=REGISTRY_STORAGE_S3_ACCESSKEY=$(mc config host ls ${CLUSTER_ID} -json | jq -r .accessKey) \
--from-literal=REGISTRY_STORAGE_S3_SECRETKEY=$(mc config host ls ${CLUSTER_ID} -json | jq -r .secretKey)
----
+
include::partial$install/registry-samples-operator.adoc[]

include::partial$install/finalize_part1.adoc[]

include::partial$install/registry-acl-fix.adoc[]

include::partial$install/finalize_part2.adoc[]
+
. Remove bootstrap bucket
+
[source,bash]
----
mc rm -r --force "${CLUSTER_ID}/${CLUSTER_ID}-bootstrap-ignition"
mc rb "${CLUSTER_ID}/${CLUSTER_ID}-bootstrap-ignition"
----
