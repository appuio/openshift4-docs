= Replace a storage node

:kubectl_extra_args: --as=cluster-admin
:delabel_app_nodes: yes
:argo_app: rook-ceph

[abstract]
--
Steps to replace a storage node of an OpenShift 4 cluster on https://www.exoscale.com[Exoscale].
--

== Starting situation

* You already have a OpenShift 4 cluster on Exoscale
* You have admin-level access to the cluster
* You want to replace an existing storage node in the cluster with a new storage node

== Prerequisites

The following CLI utilities need to be available locally:

* `docker`
* `curl`
* `kubectl`
* `oc`
* `exo` >= v1.28.0 https://community.exoscale.com/documentation/tools/exoscale-command-line-interface[Exoscale CLI]
* `vault` https://www.vaultproject.io/docs/commands[Vault CLI]
* `commodore`, see https://syn.tools/commodore/running-commodore.html[Running Commodore]
* `jq`
* `yq` https://mikefarah.gitbook.io/yq[yq YAML processor] (version 4 or higher)

== Prepare local environment

. Create local directory to work in
+
[TIP]
====
We strongly recommend creating an empty directory, unless you already have a work directory for the cluster you're about to work on.
This guide will run Commodore in the directory created in this step.
====
+
[source,bash]
----
export WORK_DIR=/path/to/work/dir
mkdir -p "${WORK_DIR}"
pushd "${WORK_DIR}"
----

. Configure API access
+
include::partial$exoscale/environment-vars.adoc[]
+
include::partial$vshn-input.adoc[]

. Get required tokens from Vault
+
include::partial$connect-to-vault.adoc[]
+
include::partial$get-hieradata-token-from-vault.adoc[]

. Compile the catalog for the cluster.
Having the catalog available locally enables us to run Terraform for the cluster to make any required changes.
+
[source,bash]
----
commodore catalog compile "${CLUSTER_ID}"
----

== Prepare Terraform environment

include::partial$exoscale/configure-terraform-secrets.adoc[]

include::partial$setup_terraform.adoc[]

== Set alert silence

:duration: +60 minutes
include::partial$create-alertmanager-silence.adoc[]

== Replace node

. Make a note of the node you want to replace
+
[source,bash]
----
export NODE_TO_REPLACE=storage-XXXX
----

=== Create a new node

. Find Terraform resource index of the node to replace
+
[source,bash]
----
# Grab JSON copy of current Terraform state
terraform state pull > .tfstate.json
node_index=$(jq --arg storage_node "${NODE_TO_REPLACE}" -r \
  '.resources[] |
   select(.module=="module.cluster.module.storage" and .type=="random_id") |
   .instances[] |
   select(.attributes.hex==$storage_node) |
   .index_key' \
  .tfstate.json)
----

. Verify that resource index is correct
+
[source,bash]
----
jq --arg index "${node_index}" -r \
  '.resources[] |
   select(.module=="module.cluster.module.storage" and .type=="exoscale_compute") |
   .instances[$index|tonumber] |
   .attributes.hostname' \
   .tfstate.json
----

. Remove node ID and node resource for node that we want to replace from the Terraform state
+
[source,bash]
----
terraform state rm "module.cluster.module.storage.random_id.node_id[$node_index]"
terraform state rm "module.cluster.module.storage.exoscale_compute.nodes[$node_index]"
----

. Run Terraform to spin up a replacement node
+
[source,bash]
----
terraform apply
----

. Approve node cert for new storage node
+
include::partial$install/approve-node-csrs.adoc[]

. Label and taint the new storage node
+
include::partial$exoscale/label-taint-storage-nodes.adoc[]

. Wait for the localstorage PV on the new node to be created
+
[source,bash]
----
kubectl --as=cluster-admin get pv \
  -l storage.openshift.com/local-volume-owner-name=storagevolumes -w
----

. Disable auto sync for component `rook-ceph`.
This allows us to temporarily make manual changes to the Rook Ceph cluster.
+
include::partial$disable-argocd-autosync.adoc[]

. Make a note of the original count of OSDs in the Ceph cluster
+
[source,bash]
----
orig_osd_count=$(kubectl --as=cluster-admin -n syn-rook-ceph-cluster \
  get cephcluster cluster -o jsonpath='{.spec.storage.storageClassDeviceSets[0].count}')
----

. Change Ceph cluster to have one more OSD
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster patch cephcluster cluster --type=json \
  -p "[{
    \"op\": \"replace\",
    \"path\": \"/spec/storage/storageClassDeviceSets/0/count\",
    \"value\": $(expr ${orig_osd_count} + 1)
  }]"
----

. Wait until the new OSD is launched
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster get pods -w
----

=== Remove old OSD

:osd-node: ${NODE_TO_REPLACE}
include::partial$storage-ceph-remove-osd.adoc[]

. Scale down the Rook-Ceph operator
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-operator scale --replicas=0 \
  deploy/rook-ceph-operator
----

. Make a note of the PVC of the old OSD
+
NOTE: We also extract the name of the PV here, but we'll only delete the PV after removing the node from the cluster.
+
[source,bash]
----
pvc_name=$(kubectl --as=cluster-admin -n syn-rook-ceph-cluster get deploy \
  "rook-ceph-osd-${OSD_ID}" -ojsonpath='{.metadata.labels.ceph\.rook\.io/pvc}')
pv_name=$(kubectl --as=cluster-admin -n syn-rook-ceph-cluster get pvc \
  "${pvc_name}" -o jsonpath='{.spec.volumeName}')
----

. Check if the OSD deployment needs to be deleted, and delete it if necessary
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster get deploy \
  -l failure-domain="${NODE_TO_REPLACE}"
# Run this command if the previous command lists a deployment
kubectl --as=cluster-admin -n syn-rook-ceph-cluster delete deploy \
  -l failure-domain="${NODE_TO_REPLACE}"
----

. Reset Ceph cluster resource to have original number of OSDs
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster patch cephcluster cluster --type=json \
  -p "[{
    \"op\": \"replace\",
    \"path\": \"/spec/storage/storageClassDeviceSets/0/count\",
    \"value\": ${orig_osd_count}
  }]"
----

. Clean up PVC and prepare job of the old OSD if necessary
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster delete job \
  -l ceph.rook.io/pvc="${pvc_name}"
kubectl --as=cluster-admin -n syn-rook-ceph-cluster delete pvc "${pvc_name}"
----

. Clean up PVC encryption secret
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster delete secret -l pvc_name="${pvc_name}"
----

. Scale up the Rook-Ceph operator
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-operator scale --replicas=1 \
  deploy/rook-ceph-operator
----

=== Remove the old MON

:argocd_disabled: true
:mon_node: ${NODE_TO_REPLACE}
include::partial$storage-ceph-remove-mon.adoc[]

=== Clean up the old node

:delete-node: ${NODE_TO_REPLACE}
include::partial$exoscale/delete-node.adoc[]

. Clean up localstorage PV of decommissioned node
+
[source,bash]
----
kubectl --as=cluster-admin delete pv "${pv_name}"
----

== Finish up

include::partial$remove-alertmanager-silence.adoc[]

include::partial$enable-argocd-autosync.adoc[]

== Upstream documentation

* Rook documentation
** https://rook.io/docs/rook/v1.6/ceph-osd-mgmt.html#remove-an-osd[Remove an OSD]
** https://rook.io/docs/rook/v1.6/ceph-mon-health.html#failing-over-a-monitor[MON failover]
