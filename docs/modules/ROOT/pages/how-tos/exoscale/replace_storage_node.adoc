= Replace a storage node

:cloud_provider: exoscale
:kubectl_extra_args: --as=cluster-admin
:delabel_app_nodes: yes
:argo_app: rook-ceph

:osd-replace-list: $NODE_TO_REPLACE

:mon-operation: replace
:mon-argocd-autosync-already-disabled: yes
:mon-replace-list: $NODE_TO_REPLACE

:node-delete-list: ${NODE_TO_REPLACE}
:delete-nodes-manually: yes
:delete-pvs: old_pv_names
:delete-node-type: storage

[abstract]
--
Steps to replace a storage node of an OpenShift 4 cluster on https://www.exoscale.com[Exoscale].
--

== Starting situation

* You already have a OpenShift 4 cluster on Exoscale
* You have admin-level access to the cluster
* You want to replace an existing storage node in the cluster with a new storage node

== Prerequisites

include::partial$exoscale/prerequisites.adoc[]

== Prepare local environment

include::partial$exoscale/setup-local-env.adoc[]

== Prepare Terraform environment

include::partial$exoscale/configure-terraform-secrets.adoc[]

include::partial$setup_terraform.adoc[]

== Set alert silence and pause ArgoCD

:duration: +60 minutes
include::partial$create-alertmanager-silence.adoc[]

. Disable auto sync for component `rook-ceph`.
This allows us to temporarily make manual changes to the Rook Ceph cluster.
+
include::partial$disable-argocd-autosync.adoc[]

== Replace node

. Make a note of the node you want to replace
+
[source,bash]
----
export NODE_TO_REPLACE=storage-XXXX
----

include::partial$create-replacement-storage-node.adoc[]

=== Remove old OSD

include::partial$storage-ceph-remove-osd.adoc[]

. Scale down the Rook-Ceph operator
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-operator scale --replicas=0 \
  deploy/rook-ceph-operator
----

. Reset Ceph cluster resource to have original number of OSDs
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-cluster patch cephcluster cluster --type=json \
  -p "[{
    \"op\": \"replace\",
    \"path\": \"/spec/storage/storageClassDeviceSets/0/count\",
    \"value\": ${orig_osd_count}
  }]"
----

include::partial$storage-ceph-cleanup-osd.adoc[]

. Scale up the Rook-Ceph operator
+
[source,bash]
----
kubectl --as=cluster-admin -n syn-rook-ceph-operator scale --replicas=1 \
  deploy/rook-ceph-operator
----

=== Remove the old MON

include::partial$storage-ceph-remove-mon.adoc[]

=== Clean up the old node

include::partial$drain-node-immediately.adoc[]

include::partial$delete-node-vm.adoc[]

== Finish up

include::partial$remove-alertmanager-silence.adoc[]

include::partial$enable-argocd-autosync.adoc[]

== Upstream documentation

* Rook documentation
** https://rook.io/docs/rook/v1.7/ceph-osd-mgmt.html#remove-an-osd[Remove an OSD]
** https://rook.io/docs/rook/v1.7/ceph-mon-health.html#failing-over-a-monitor[MON failover]
